{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEERFold Examples\n",
    "\n",
    "In this notebook we will overview how to approach the following topics: \n",
    "\n",
    "* Unconstrained prediction \n",
    "* Constrained prediction \n",
    "\n",
    "## Unconstrained prediction\n",
    "\n",
    "For comparison DEERFold can accept empty csv file to genreate unconstrained models. \n",
    "\n",
    "To unconditionally generate models from DEERFold, required parameters are as follows:\n",
    "- `fasta_file`: Input sequence file in FASTA format.\n",
    "- `msa_dir`: Directory containing multiple sequence alignments.\n",
    "- `out_dir`: Directory to save output models.\n",
    "- `model`: Directory storing all the model weights.\n",
    "- `neff`: MSA Neff value.\n",
    "- `num`: Number of models to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'your_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19348/733214923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import necessary modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myour_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_with_sp_batch\u001b[0m  \u001b[0;31m# Replace 'your_module' with the actual module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_fasta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"examples/PfMATE.fasta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'your_module'"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from your_module import predict_with_sp_batch  # Replace 'your_module' with the actual module name\n",
    "\n",
    "# Define parameters\n",
    "input_fasta = \"examples/PfMATE.fasta\"\n",
    "output_dir = \"examples/alignments\"\n",
    "model_type = \"strand\"\n",
    "neff = 5\n",
    "num = 100\n",
    "\n",
    "# Load the model and other necessary components\n",
    "# Note: You might need to adjust this part based on how your model is loaded\n",
    "model, collater, tokenizer, scheme = predict_with_sp_batch.load_model(model_type)\n",
    "\n",
    "# Run the prediction\n",
    "results = predict_with_sp_batch.predict(\n",
    "    input_fasta=input_fasta,\n",
    "    output_dir=output_dir,\n",
    "    model=model,\n",
    "    collater=collater,\n",
    "    tokenizer=tokenizer,\n",
    "    scheme=scheme,\n",
    "    neff=neff,\n",
    "    num_sequences=num_sequences\n",
    ")\n",
    "\n",
    "# Display or process results\n",
    "print(f\"Prediction completed. Results saved in {output_dir}\")\n",
    "print(f\"Number of sequences processed: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained prediction\n",
    "\n",
    "### Input Format\n",
    "DEERFold can accept input DEER distance constraints in csv format, the format is shown as below:\n",
    "```\n",
    "18,95,0,0,0,0,2.00E-05,7.00E-05,0.00027,0.0009,0.0027,0.00708,0.01622,0,0,0,0,...\n",
    "18,215,0,0,0,0,0,0,8.00E-05,0.000940009,0.007260073,0.035440354,0.109791098,0.215792158,...\n",
    "18,240,0,0,1.00E-05,4.00E-05,0.000169995,0.00067998,0.00233993,0.006879794,0.017259482,...\n",
    "```\n",
    "\n",
    "The constraints are in the format of distograms across 100 bins (shape LxLx100):\n",
    "- Bin 1: Less than or equal to 1.5 Å\n",
    "- Bin 2: (1.5 Å, 2.5 Å] \n",
    "- Bin 3: (2.5 Å, 3.5 Å] \n",
    "- ...\n",
    "- Bin 99: (98.5 Å, 99.5 Å]\n",
    "- Bin 100: Greater than 99.5 Å\n",
    "\n",
    "To run inference on a sequence with the given DEER constraints, make sure you have the following:\n",
    "- `fasta_file`: Input sequence file in FASTA format.\n",
    "- `msa_dir`: Directory containing multiple sequence alignments.\n",
    "- `out_dir`: Directory to save output models.\n",
    "- `model`: Directory storing all the model weights.\n",
    "- `sp`: Input file with DEER constraints in CSV format.\n",
    "- `neff`: MSA Neff value.\n",
    "- `num`: Number of models to generate.\n",
    "- `refs`: Reference PDB files for RMSD and TM-score analysis (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'your_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19348/53613856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myour_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_with_sp_batch\u001b[0m  \u001b[0;31m# Replace 'your_module' with the actual module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfasta_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"examples/PfMATE/PfMATE.fasta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'your_module'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from your_module import predict_with_sp_batch  # Replace 'your_module' with the actual module name\n",
    "\n",
    "# Define parameters\n",
    "fasta_file = \"examples/PfMATE/PfMATE.fasta\"\n",
    "msa_dir = \"examples/alignments\"\n",
    "out_dir = \"out/PfMATE\"\n",
    "model_weights_dir = \"model\"\n",
    "csv_file = \"examples/PfMATE/PfMATE_low.csv\"\n",
    "neff = 5\n",
    "num_models = 100\n",
    "ref_pdbs = [\"examples/PfMATE/6gwh.pdb\", \"examples/PfMATE/6fhz.pdb\"]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Run prediction\n",
    "results = predict_with_sp_batch(\n",
    "    fasta_file=fasta_file,\n",
    "    msa_dir=msa_dir,\n",
    "    out_dir=out_dir,\n",
    "    model=model_weights_dir,\n",
    "    sp=csv_file,\n",
    "    neff=neff,\n",
    "    num=num_models,\n",
    "    refs=\",\".join(ref_pdbs)\n",
    ")\n",
    "\n",
    "print(f\"Prediction completed. Results saved in {out_dir}\")\n",
    "print(f\"Number of models generated: {num_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "DEERFold will generate predicted models in PDB format. These models are ranked by EMD distance between the prediction and the input distance constraints. The top-ranking models should be those most closely fitting the input distance constraints.\n",
    "\n",
    "### Analyzing Results\n",
    "\n",
    "After running the prediction, you can analyze the results by examining the output PDB files in the specified output directory. If you provided reference PDB files, DEERFold will also perform RMSD and TM-score analysis comparing the predictions to these references.\n",
    "\n",
    "To visualize or further analyze the top models, you can use various protein structure visualization tools or additional analysis scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphalink_venv",
   "language": "python",
   "name": "alphalink_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
